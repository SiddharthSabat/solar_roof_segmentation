{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a53505c-4223-48ef-8905-ec76fd50fbcd",
   "metadata": {},
   "source": [
    "## Training with Validation Split and CNN with VGG Net Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54934841-935a-414c-9682-9ba78c11eb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 13:26:25.043030: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-25 13:26:25.921727: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal\n",
    "#import gdal\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate, Reshape\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "#import tifffile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Activation, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2012a1-9e3e-47a8-9c55-cca3737a2246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 12:43:12.779742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-25 12:43:12.839462: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8323c178-46bc-4888-b3ac-8966e344c988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ssabat/code/SiddharthSabat/solar_roof_segmentation\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f868ffd-1e02-4bf6-afda-720b286fa94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55140905-11ef-4f4f-98f4-d7bc4df05ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def move_files(source_folder, destination_folder, file_prefix):\n",
    "  # Get a list of all files in the source folder\n",
    "  files = os.listdir(source_folder)\n",
    "\n",
    "  # Create the destination folder if it doesn't exist\n",
    "  if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "    \n",
    "  # Iterate over each file\n",
    "  for file_name in files:\n",
    "    # Check if the file name starts with the specified prefix\n",
    "    if file_name.startswith(file_prefix):\n",
    "      #print(file_name)\n",
    "      # Construct the full path of the source file\n",
    "      source_path = os.path.join(source_folder, file_name)\n",
    "\n",
    "      # Construct the full path of the destination file\n",
    "      destination_path = os.path.join(destination_folder, file_name)\n",
    "\n",
    "      # Move the file to the destination folder\n",
    "      shutil.move(source_path, destination_path)\n",
    "      #print(f\"Moved {file_name} to {destination_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6629a74a-692a-4776-bc3d-481ed8c8e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "source_folder = 'data/test_patch'\n",
    "destination_folder = 'data/test_patch/bellingham'\n",
    "file_prefix = 'bellingham'\n",
    "\n",
    "move_files(source_folder, destination_folder, file_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc45e00-0d55-401e-a9c8-556f961ece15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "source_folder = 'data/test_patch'\n",
    "destination_folder = 'data/test_patch/bloomington'\n",
    "file_prefix = 'bloomington'\n",
    "\n",
    "move_files(source_folder, destination_folder, file_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f0f8878-5f80-4033-8c34-889a50292e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "source_folder = 'data/test_patch'\n",
    "destination_folder = 'data/test_patch/innsbruck'\n",
    "file_prefix = 'innsbruck'\n",
    "\n",
    "move_files(source_folder, destination_folder, file_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd6e1d98-b0ab-418f-99ef-6f64924039cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "source_folder = 'data/test_patch'\n",
    "destination_folder = 'data/test_patch/sfo'\n",
    "file_prefix = 'sfo'\n",
    "\n",
    "move_files(source_folder, destination_folder, file_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec6fe089-b99d-4366-a267-b166607df72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "source_folder = 'data/test_patch'\n",
    "destination_folder = 'data/test_patch/tyrol'\n",
    "file_prefix = 'tyrol'\n",
    "\n",
    "move_files(source_folder, destination_folder, file_prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ae5df-339a-4bc7-9b50-f2883231833c",
   "metadata": {},
   "source": [
    "## Load the patched images using Image data generator with validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "839d8fd6-8a21-4621-86a7-358ad25ea307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46660 images belonging to 5 classes.\n",
      "Found 11660 images belonging to 5 classes.\n",
      "Found 46660 images belonging to 5 classes.\n",
      "Found 11660 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the paths to your image data directories\n",
    "x_train_dir = 'data/train_patch/'\n",
    "y_train_dir = 'data/train_label_patch/'\n",
    "\n",
    "# Set the image and batch size\n",
    "image_size = (512, 512)  # Target image size for resizing\n",
    "batch_size = 32\n",
    "\n",
    "# Data augmentation and normalization configuration for x_train\n",
    "x_train_generator = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # Scale pixel values to [0, 1]\n",
    "    rotation_range=20,  # Random rotation between -20 and 20 degrees\n",
    "    width_shift_range=0.2,  # Randomly shift images horizontally by 20% of the width\n",
    "    height_shift_range=0.2,  # Randomly shift images vertically by 20% of the height\n",
    "    horizontal_flip=True  # Randomly flip images horizontally\n",
    "    ,validation_split=0.2\n",
    ")\n",
    "\n",
    "# Create an image generator for x_train\n",
    "x_train_image_generator = x_train_generator.flow_from_directory(\n",
    "    x_train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,  # Set to None to return only input images\n",
    "    shuffle=False  # Set to False to ensure x_train and y_train match\n",
    "    ,subset='training'\n",
    ")\n",
    "x_val = x_train_generator.flow_from_directory(\n",
    "    x_train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,  # Set to None to return only input images\n",
    "    #class_mode='binary',\n",
    "    subset='validation',  # Subset for validation data\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Data normalization configuration for y_train\n",
    "y_train_generator = ImageDataGenerator(\n",
    "    rescale=1.0 / 255  # Scale pixel values to [0, 1]\n",
    "    ,validation_split=0.2\n",
    ")\n",
    "\n",
    "# Create an image generator for y_train\n",
    "y_train_image_generator = y_train_generator.flow_from_directory(\n",
    "    y_train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,  # Set to None to return only input images\n",
    "    shuffle=False  # Set to False to ensure x_train and y_train match\n",
    "    ,subset='training'\n",
    ")\n",
    "\n",
    "y_val = y_train_generator.flow_from_directory(\n",
    "    y_train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,  # Set to None to return only input images\n",
    "    subset='validation',  # Subset for validation data\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Ensure x_train and y_train generators have the same number of samples\n",
    "assert len(x_train_image_generator) == len(y_train_image_generator), \"Mismatch in x_train and y_train data\"\n",
    "train_data_generator = zip(x_train_image_generator, y_train_image_generator)\n",
    "val_data_generator =   zip(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b26fdf-8b01-4deb-ab0f-f849b1530a1d",
   "metadata": {},
   "source": [
    "### Model Architecture and Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e862ed1f-d3d4-482b-90d8-6697ea5f4c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    def dice_loss(y_true, y_pred):\n",
    "        y_pred = tf.math.sigmoid(y_pred)\n",
    "        numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "        denominator = tf.reduce_sum(y_true + y_pred)\n",
    "        return 1 - numerator / denominator\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    cross_entropy_loss = tf.nn.sigmoid_cross_entropy_with_logits(y_true, y_pred)\n",
    "    total_loss = cross_entropy_loss + dice_loss(y_true, y_pred)\n",
    "    return tf.reduce_mean(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a254b6a-7957-48ab-8447-f36901a66a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true, y_pred):\n",
    "    y_pred = tf.math.round(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    union = K.sum(y_true) + K.sum(y_pred) - intersection\n",
    "    iou = intersection / (union + K.epsilon())\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e7fb218-28ba-487b-96d1-b2bbc1b2d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet:\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self.build_vgg19_unet()\n",
    "    def conv_block(self, input, num_filters):\n",
    "        x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        return x\n",
    "    def decoder_block(self, input, skip_features, num_filters):\n",
    "        x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "        x = Concatenate()([x, skip_features])\n",
    "        x = self.conv_block(x, num_filters)\n",
    "        return x\n",
    "    def build_vgg19_unet(self):\n",
    "        \"\"\" Input \"\"\"\n",
    "        inputs = Input(self.input_shape)\n",
    "        \"\"\" Pre-trained VGG19 Model \"\"\"\n",
    "        vgg19 = VGG19(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        s1 = vgg19.get_layer(\"block1_conv2\").output       ## (512 x 512)\n",
    "        s2 = vgg19.get_layer(\"block2_conv2\").output       ## (256 x 256)\n",
    "        s3 = vgg19.get_layer(\"block3_conv4\").output       ## (128 x 128)\n",
    "        s4 = vgg19.get_layer(\"block4_conv4\").output       ## (64 x 64)\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        b1 = vgg19.get_layer(\"block5_conv4\").output       ## (32 x 32)\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.decoder_block(b1, s4, 512)              ## (64 x 64)\n",
    "        d2 = self.decoder_block(d1, s3, 256)              ## (128 x 128)\n",
    "        d3 = self.decoder_block(d2, s2, 128)              ## (256 x 256)\n",
    "        d4 = self.decoder_block(d3, s1, 64)               ## (512 x 512)\n",
    "        \"\"\" Output \"\"\"\n",
    "        outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "        model = Model(inputs, outputs, name=\"VGG19_U-Net\")\n",
    "        return model\n",
    "    \n",
    "    def compile(self, optimizer='adam'):\n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "        \n",
    "    def train(self, train_data_generator, val_data_generator,steps_per_epoch, epochs, batch_size):\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=loss, metrics=['accuracy', iou_metric])\n",
    "        lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001, verbose=1)\n",
    "        #self.model.fit(x, y, epochs=epochs, batch_size=batch_size, validation_split = 0.2 , callbacks=[lr_reducer])\n",
    "        #self.model.fit(train_data_generator, steps_per_epoch=len(x_train_image_generator), epochs=2, batch_size = 32, verbose=1, validation_split = 0.2)\n",
    "               \n",
    "        # Use the generator to train the model\n",
    "        self.model.fit(train_data_generator, validation_data = val_data_generator, steps_per_epoch=steps_per_epoch, epochs=1, batch_size = batch_size, verbose=1, callbacks=[lr_reducer])\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2251f6a-87fa-45d6-aa34-46dc5285a2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG19_U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 512, 512, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 512, 512, 64  36928       ['block1_conv1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 256, 256, 64  0           ['block1_conv2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 256, 256, 12  73856       ['block1_pool[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 256, 256, 12  147584      ['block2_conv1[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 128, 128, 12  0           ['block2_conv2[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 128, 128, 25  295168      ['block2_pool[0][0]']            \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 128, 128, 25  590080      ['block3_conv1[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 128, 128, 25  590080      ['block3_conv2[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " block3_conv4 (Conv2D)          (None, 128, 128, 25  590080      ['block3_conv3[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 64, 64, 256)  0           ['block3_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 64, 64, 512)  1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 64, 64, 512)  2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 64, 64, 512)  2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv4 (Conv2D)          (None, 64, 64, 512)  2359808     ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 32, 32, 512)  0           ['block4_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 32, 32, 512)  2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 32, 32, 512)  2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 32, 32, 512)  2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv4 (Conv2D)          (None, 32, 32, 512)  2359808     ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 64, 64, 512)  1049088    ['block5_conv4[0][0]']           \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64, 64, 1024  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'block4_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 64, 64, 512)  4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 64, 64, 512)  2048       ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 64, 64, 512)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 64, 512)  2359808     ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 64, 64, 512)  2048       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 64, 64, 512)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 25  524544     ['activation_1[0][0]']           \n",
      " spose)                         6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128, 128, 51  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                2)                                'block3_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 25  1179904     ['concatenate_1[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_2[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 128, 128, 25  0           ['batch_normalization_2[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 25  590080      ['activation_2[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_3[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 128, 128, 25  0           ['batch_normalization_3[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 12  131200     ['activation_3[0][0]']           \n",
      " spose)                         8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256, 256, 25  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                6)                                'block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 256, 256, 12  295040      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 256, 256, 12  512        ['conv2d_4[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 256, 256, 12  0           ['batch_normalization_4[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 256, 256, 12  147584      ['activation_4[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 256, 256, 12  512        ['conv2d_5[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 256, 256, 12  0           ['batch_normalization_5[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 512, 512, 64  32832      ['activation_5[0][0]']           \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 512, 512, 12  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                8)                                'block1_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 512, 512, 64  73792       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 512, 512, 64  256        ['conv2d_6[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 512, 512, 64  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 512, 512, 64  36928       ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 512, 512, 64  256        ['conv2d_7[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 512, 512, 64  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 512, 512, 1)  65          ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,172,033\n",
      "Trainable params: 31,168,193\n",
      "Non-trainable params: 3,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch=len(x_train_image_generator)\n",
    "input_shape = (512, 512, 3)\n",
    "batch_size = 32\n",
    "unet = UNet(input_shape)\n",
    "# Compile the model\n",
    "unet.compile(optimizer='adam')\n",
    "# Print the model summary\n",
    "unet.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4419b5-83db-4eaf-827b-e189f1942cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 11:02:36.178527: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-25 11:03:16.561225: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4294967296 exceeds 10% of free system memory.\n",
      "2023-05-25 11:03:36.597063: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4294967296 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/1459 [..............................] - ETA: 70:55:41 - loss: 1.5204 - accuracy: 0.4726 - iou_metric: 0.4312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 11:06:08.404097: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4294967296 exceeds 10% of free system memory.\n",
      "2023-05-25 11:06:33.039885: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4294967296 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/1459 [..............................] - ETA: 77:02:23 - loss: 1.5090 - accuracy: 0.5370 - iou_metric: 0.3756"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 11:09:22.553651: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4294967296 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  14/1459 [..............................] - ETA: 69:10:23 - loss: 1.4618 - accuracy: 0.7008 - iou_metric: 0.1598"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 2\n",
    "batch_size = 32\n",
    "unet.train(train_data_generator, val_data_generator, steps_per_epoch, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f210f6-69f0-4c0d-8f8f-6240917bd79d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
