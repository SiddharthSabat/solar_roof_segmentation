{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4449ade-21cf-4887-97c8-93ce52da2a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 16:12:45.223858: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-23 16:12:45.310055: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-23 16:12:45.310066: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-23 16:12:45.327113: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-05-23 16:12:45.799300: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-23 16:12:45.799375: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-23 16:12:45.799382: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal\n",
    "#import gdal\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate, Reshape\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "#import tifffile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6226a9-5c07-490e-89a4-72e08697e65f",
   "metadata": {},
   "source": [
    "### Patchng sample code for one image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10220938-29bf-4aae-848a-b79604794340",
   "metadata": {},
   "source": [
    "import os\n",
    "from osgeo import gdal, gdal_array\n",
    "\n",
    "input_path = \"data/train/images/austin1.tif\"\n",
    "output_path = \"data/test_image.tif\"\n",
    "\n",
    "patch_size = 256\n",
    "overlap = 128\n",
    "\n",
    "dataset = gdal.Open(input_path, gdal.GA_ReadOnly)\n",
    "width = dataset.RasterXSize\n",
    "height = dataset.RasterYSize\n",
    "bands = dataset.RasterCount\n",
    "\n",
    "num_patches_x = (width - overlap) // (patch_size - overlap)\n",
    "num_patches_y = (height - overlap) // (patch_size - overlap)\n",
    "\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "for i in range(num_patches_x):\n",
    "    for j in range(num_patches_y):\n",
    "        x_start = i * (patch_size - overlap)\n",
    "        y_start = j * (patch_size - overlap)\n",
    "        x_end = x_start + patch_size\n",
    "        y_end = y_start + patch_size\n",
    "        \n",
    "        patch_data = dataset.ReadAsArray(x_start, y_start, patch_size, patch_size)\n",
    "        \n",
    "        patch_output_path = f\"{output_path}_{i}_{j}.tif\"\n",
    "        \n",
    "        driver = gdal.GetDriverByName(\"GTiff\")\n",
    "        patch_output = driver.Create(\n",
    "            patch_output_path,\n",
    "            patch_size,\n",
    "            patch_size,\n",
    "            bands,\n",
    "            gdal_array.NumericTypeCodeToGDALTypeCode(patch_data.dtype)\n",
    "        )\n",
    "        patch_output.SetGeoTransform(dataset.GetGeoTransform())\n",
    "        patch_output.SetProjection(dataset.GetProjection())\n",
    "        \n",
    "        for k in range(bands):\n",
    "            patch_output.GetRasterBand(k + 1).WriteArray(patch_data[k])\n",
    "        \n",
    "        patch_output.FlushCache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b35d3-9b5b-40cc-84d1-fd465be8209c",
   "metadata": {},
   "source": [
    "### Do not run untill there is a need to generate the patch images for train, label and test images.\n",
    "***************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a75133ad-ac7d-40dd-82e2-b8b971e185bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from osgeo import gdal, gdal_array\n",
    "\n",
    "def patch_images(input_dir, output_dir, patch_size, overlap):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get a list of all image files in the input directory\n",
    "    image_files = [f for f in os.listdir(input_dir) if f.endswith('.tif')]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        # Construct the input and output file paths\n",
    "        input_path = os.path.join(input_dir, image_file)\n",
    "\n",
    "        # Open the input image using GDAL and get its properties\n",
    "        dataset = gdal.Open(input_path, gdal.GA_ReadOnly)\n",
    "        if dataset is None:\n",
    "            print(f\"Error opening {input_path}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        width = dataset.RasterXSize\n",
    "        height = dataset.RasterYSize\n",
    "        bands = dataset.RasterCount\n",
    "\n",
    "        # Calculate the number of patches in each dimension\n",
    "        num_patches_x = (width - overlap) // (patch_size - overlap)\n",
    "        num_patches_y = (height - overlap) // (patch_size - overlap)\n",
    "\n",
    "        for i in range(num_patches_x):\n",
    "            for j in range(num_patches_y):\n",
    "                x_start = i * (patch_size - overlap)\n",
    "                y_start = j * (patch_size - overlap)\n",
    "                x_end = x_start + patch_size\n",
    "                y_end = y_start + patch_size\n",
    "\n",
    "                patch_data = dataset.ReadAsArray(x_start, y_start, patch_size, patch_size)\n",
    "\n",
    "                patch_output_path = os.path.join(\n",
    "                    output_dir, f\"{os.path.splitext(image_file)[0]}_{i}_{j}.tif\"\n",
    "                )\n",
    "\n",
    "                driver = gdal.GetDriverByName(\"GTiff\")\n",
    "                patch_output = driver.Create(\n",
    "                    patch_output_path,\n",
    "                    patch_size,\n",
    "                    patch_size,\n",
    "                    bands,\n",
    "                    gdal_array.NumericTypeCodeToGDALTypeCode(patch_data.dtype)\n",
    "                )\n",
    "\n",
    "                # Set the geotransform and projection from the input image\n",
    "                patch_output.SetGeoTransform(dataset.GetGeoTransform())\n",
    "                patch_output.SetProjection(dataset.GetProjection())\n",
    "\n",
    "                for k in range(bands):\n",
    "                    patch_output.GetRasterBand(k + 1).WriteArray(patch_data[k])\n",
    "\n",
    "                patch_output.FlushCache()\n",
    "\n",
    "        dataset = None  # Close the input image dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b5ae06-1eda-4d50-94b3-7f4eb0c50006",
   "metadata": {},
   "source": [
    "### Loading for the train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c070b6a7-ba6f-4149-b0b2-3f12608001b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the input and output directories and patch parameters\n",
    "input_directory = 'data/train/images/'\n",
    "output_directory = \"data/train_patch/\"\n",
    "patch_size = 512\n",
    "overlap = 256\n",
    "\n",
    "# Patch the images in the directory\n",
    "patch_images(input_directory, output_directory, patch_size, overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf274c-99ce-47e7-9415-843c85a4effb",
   "metadata": {},
   "source": [
    "### Loading for the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8bbce05-a22c-4dec-8993-78a094b41508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input and output directories and patch parameters\n",
    "input_directory = 'data/test/images/'\n",
    "output_directory = \"data/test_patch/\"\n",
    "patch_size = 512\n",
    "overlap = 256\n",
    "\n",
    "# Patch the images in the directory\n",
    "patch_images(input_directory, output_directory, patch_size, overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302636d4-16b9-4fb6-b41f-56121461e3f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading for the train labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb359d13-c52c-4a38-945c-3150364d9eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from osgeo import gdal, gdal_array\n",
    "\n",
    "def patch_images_gs(input_dir, output_dir, patch_size, overlap):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get a list of all image files in the input directory\n",
    "    image_files = [f for f in os.listdir(input_dir) if f.endswith('.tif')]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        # Construct the input and output file paths\n",
    "        input_path = os.path.join(input_dir, image_file)\n",
    "\n",
    "        # Open the input image using GDAL and get its properties\n",
    "        dataset = gdal.Open(input_path, gdal.GA_ReadOnly)\n",
    "        if dataset is None:\n",
    "            print(f\"Error opening {input_path}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        width = dataset.RasterXSize\n",
    "        height = dataset.RasterYSize\n",
    "        bands = dataset.RasterCount\n",
    "\n",
    "        # Make sure the input image is grayscale (single band)\n",
    "        if bands != 1:\n",
    "            print(f\"Input image {input_path} is not grayscale. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Calculate the number of patches in each dimension\n",
    "        num_patches_x = (width - overlap) // (patch_size - overlap)\n",
    "        num_patches_y = (height - overlap) // (patch_size - overlap)\n",
    "\n",
    "        for i in range(num_patches_x):\n",
    "            for j in range(num_patches_y):\n",
    "                x_start = i * (patch_size - overlap)\n",
    "                y_start = j * (patch_size - overlap)\n",
    "                x_end = x_start + patch_size\n",
    "                y_end = y_start + patch_size\n",
    "\n",
    "                patch_data = dataset.ReadAsArray(x_start, y_start, patch_size, patch_size)\n",
    "\n",
    "                patch_output_path = os.path.join(\n",
    "                    output_dir, f\"{os.path.splitext(image_file)[0]}_{i}_{j}.tif\"\n",
    "                )\n",
    "\n",
    "                driver = gdal.GetDriverByName(\"GTiff\")\n",
    "                patch_output = driver.Create(\n",
    "                    patch_output_path,\n",
    "                    patch_size,\n",
    "                    patch_size,\n",
    "                    bands,\n",
    "                    gdal_array.NumericTypeCodeToGDALTypeCode(patch_data.dtype)\n",
    "                )\n",
    "\n",
    "                # Set the geotransform and projection from the input image\n",
    "                patch_output.SetGeoTransform(dataset.GetGeoTransform())\n",
    "                patch_output.SetProjection(dataset.GetProjection())\n",
    "\n",
    "                patch_output.GetRasterBand(1).WriteArray(patch_data)\n",
    "\n",
    "                patch_output.FlushCache()\n",
    "\n",
    "        dataset = None  # Close the input image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fca0d2b7-bb16-40d1-8eda-b2bcddf3b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input and output directories and patch parameters\n",
    "input_directory = 'data/train/gt/'\n",
    "output_directory = \"data/train_label_patch/\"\n",
    "patch_size = 512\n",
    "overlap = 256\n",
    "\n",
    "# Patch the images in the directory\n",
    "patch_images_gs(input_directory, output_directory, patch_size, overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3d8dbe-8820-4f83-8f8f-a46901e437a7",
   "metadata": {},
   "source": [
    "***************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0aca1b-690e-489d-bfb0-a8cdab87a435",
   "metadata": {},
   "source": [
    "### Code for the full data load - Do not delete"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0db7d53b-0ab1-43bf-b52a-b08eecad0de6",
   "metadata": {},
   "source": [
    "# Set the data directory\n",
    "data_dir = 'data/train/images/'\n",
    "\n",
    "# Load the image dataset\n",
    "images = load_dataset(data_dir)\n",
    "\n",
    "# Normalize the images (optional, depending on your data)\n",
    "images = images / 255.0\n",
    "\n",
    "\n",
    "# Load thelabels (ground truth) dataset in a similar way\n",
    "labels_dir = 'data/train/gt/'\n",
    "labels = load_dataset(labels_dir)\n",
    "labels = labels/255\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(train_images) * split_ratio)\n",
    "\n",
    "train_images = train_images[:split_index]\n",
    "train_labels = labels_images[:split_index]\n",
    "val_images = train_images[split_index:]\n",
    "val_labels = labels_images[split_index:]\n",
    "\n",
    "# Define the input shape of the model\n",
    "input_shape = train_images[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac88b7-b080-4df4-b952-1afeb2d098ca",
   "metadata": {},
   "source": [
    "### Load the data from the patch folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d2b868e-b266-4815-8548-824336c2cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load image data using GDAL\n",
    "def load_image(image_path):\n",
    "    dataset = gdal.Open(image_path, gdal.GA_ReadOnly)\n",
    "    image_data = dataset.ReadAsArray()\n",
    "    dataset = None\n",
    "    return image_data\n",
    "\n",
    "# Function to load image dataset\n",
    "def load_dataset(data_dir):\n",
    "    # Get list of image file paths\n",
    "    image_files = [f for f in os.listdir(data_dir) if f.endswith('.tif')]\n",
    "\n",
    "    # Load images and concatenate into a single numpy array\n",
    "    images = []\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(data_dir, image_file)\n",
    "        image_data = load_image(image_path)\n",
    "        images.append(image_data)\n",
    "    images = np.stack(images, axis=0)\n",
    "\n",
    "    return images\n",
    "\n",
    "# Function to load a subset of the dataset\n",
    "def load_subset(data_dir, start_index, end_index):\n",
    "    image_files = [f for f in os.listdir(data_dir) if f.endswith('.tif')]\n",
    "    images = []\n",
    "    for i in range(start_index, end_index):\n",
    "        image_file = image_files[i]\n",
    "        image_path = os.path.join(data_dir, image_file)\n",
    "        image_data = load_image(image_path)\n",
    "        images.append(image_data)\n",
    "    images = np.stack(images, axis=0)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f88719-3316-4484-b2a9-5048beae2c2d",
   "metadata": {},
   "source": [
    "### Load raw images using batch wise"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f65b2cc-a07f-4f47-a2b8-62bfed059a05",
   "metadata": {},
   "source": [
    "# Set the data directory\n",
    "data_dir = 'data/train_patch/'\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 20\n",
    "\n",
    "# Load and process data in batches\n",
    "num_images = len(os.listdir(data_dir))\n",
    "for start_index in range(0, num_images, batch_size):\n",
    "    end_index = min(start_index + batch_size, num_images)\n",
    "    train_images = load_subset(data_dir, start_index, end_index)\n",
    "\n",
    "train_images = train_images / 255.0    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0105e2f-f5c1-4f40-8d4a-ff128c1e3355",
   "metadata": {},
   "source": [
    "# Set the data directory\n",
    "labels_dir = 'data/train_label_patch/'\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 20\n",
    "\n",
    "# Load and process data in batches\n",
    "num_images = len(os.listdir(labels_dir))\n",
    "for start_index in range(0, num_images, batch_size):\n",
    "    end_index = min(start_index + batch_size, num_images)\n",
    "    labels_images = load_subset(labels_dir, start_index, end_index)\n",
    "\n",
    "labels_images = labels_images/255.0    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0605d8a0-7380-4008-88da-e42b277c4426",
   "metadata": {},
   "source": [
    "### Sliting the data if raw images or raw batch of images to be trained"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6ecd21f-ba90-41b8-a83c-c446c58748c5",
   "metadata": {},
   "source": [
    "# Split the dataset into training and validation sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(train_images) * split_ratio)\n",
    "\n",
    "train_images = train_images[:split_index]\n",
    "train_labels = labels_images[:split_index]\n",
    "val_images = train_images[split_index:]\n",
    "val_labels = labels_images[split_index:]\n",
    "\n",
    "# Define the input shape of the model\n",
    "input_shape = train_images[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bfe13f6-bd2d-4169-b11f-6760355e980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def train_generator(x_train_dir, y_train_dir, target_size=(128, 128), batch_size=32):\n",
    "    \"\"\"A generator that returns image and mask arrays.\n",
    "    \n",
    "    Args:\n",
    "    x_train_dir (str): Directory of the training images.\n",
    "    y_train_dir (str): Directory of the ground truth masks.\n",
    "    target_size (tuple): Size of the images/masks that the generator should return.\n",
    "    batch_size (int): Number of samples per batch.\n",
    "    \"\"\"\n",
    "    \n",
    "    # List of file names\n",
    "    x_filenames = os.listdir(x_train_dir)\n",
    "    y_filenames = os.listdir(y_train_dir)\n",
    "\n",
    "    # Total number of samples\n",
    "    total_samples = len(x_filenames)\n",
    "    \n",
    "    # Ensure that we have the same number of images and masks\n",
    "    assert len(x_filenames) == len(y_filenames), \\\n",
    "    'Number of training images and masks should be the same.'\n",
    "    \n",
    "    while True:\n",
    "        # Shuffle indices to minimize overfitting\n",
    "        indices = np.random.permutation(total_samples)\n",
    "        \n",
    "        # Create batches\n",
    "        for i in range(0, total_samples, batch_size):\n",
    "            batch_indices = indices[i:i+batch_size]\n",
    "            \n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "            \n",
    "            for j in batch_indices:\n",
    "                # Load image and mask\n",
    "                x_path = os.path.join(x_train_dir, x_filenames[j])\n",
    "                y_path = os.path.join(y_train_dir, y_filenames[j])\n",
    "                \n",
    "                x = load_img(x_path, target_size=target_size)  # this is PIL image\n",
    "                y = load_img(y_path, target_size=target_size, color_mode='grayscale')  # grayscale for masks\n",
    "                \n",
    "                # Convert PIL image to numpy array\n",
    "                x = img_to_array(x)\n",
    "                y = img_to_array(y)\n",
    "                \n",
    "                # Normalize\n",
    "                x /= 255.\n",
    "                y /= 255.\n",
    "                \n",
    "                batch_x.append(x)\n",
    "                batch_y.append(y)\n",
    "            \n",
    "            batch_x = np.array(batch_x)\n",
    "            batch_y = np.array(batch_y)\n",
    "            \n",
    "            yield (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fd09c6f-afb9-4ee4-a080-b0b71d6dfaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define directories\n",
    "x_train_dir = 'data/train_patch/'\n",
    "y_train_dir = 'data/train_label_patch'\n",
    "\n",
    "# Image size you want to generate\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "\n",
    "# Instantiate the generator\n",
    "generator = train_generator(x_train_dir, y_train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48b28a05-c439-45ee-966d-edb8a3d6cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def unet_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Encoder\n",
    "    #model.add(layers.Reshape((5000*5000*3, ), input_shape=(5000,5000, 3)))\n",
    "    #model.add(Reshape((5000*5000*3,), input_shape=(5000,5000,3))) \n",
    "\n",
    "    model.add(Conv2D(64, 3, activation='relu', padding='same', input_shape = ((5000, 5000, 3))))\n",
    "    model.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
    "    #model.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
    "    #model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, 3, activation='relu', padding='same'))\n",
    "    #model.add(Conv2D(256, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Decoder\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    #model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
    "\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    #model.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
    "\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(1, 3, activation='sigmoid', padding='same'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ec50574-b849-4405-a42b-d6812b079b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 16:13:51.904480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-23 16:13:51.904593: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-23 16:13:51.904638: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-23 16:13:51.904680: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-23 16:13:51.904721: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-23 16:13:51.904762: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-23 16:13:51.904803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-23 16:13:51.904843: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-23 16:13:51.904884: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-05-23 16:13:51.904890: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-23 16:13:51.905294: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Create the U-Net model\n",
    "model = unet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4e3254-8284-42a7-a044-f7247f08e9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 16:13:55.119937: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 51200000000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Use the generator to train the model\n",
    "history = model.fit(generator, epochs=1, steps_per_epoch=5, verbose = 1, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4361e7e-d70b-444b-afcb-0af748df74f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images_reshaped = train_images.reshape((len(train_images), 5000, 5000, 3))\n",
    "#train_labels_reshaped = train_labels.reshape((len(train_labels), 5000, 5000, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3faacf8f-f102-4fb9-ac0c-375e53819129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images = train_images.reshape((16,5000, 5000, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ad93797-f669-413a-b54f-ce27eb53c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_labels =train_labels.reshape((16,5000, 5000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730a25b-3311-4cab-be0f-a768edc1a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_images, val_labels)\n",
    "print('Validation Loss:', loss)\n",
    "print('Validation Accuracy:', accuracy)\n",
    "\n",
    "# Plot the training and validation loss curves\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b328a02-cd83-4c28-9825-121aaa7d0739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save(\"roof_suitability_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
