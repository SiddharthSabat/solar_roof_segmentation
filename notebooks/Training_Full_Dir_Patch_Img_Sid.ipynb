{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a53505c-4223-48ef-8905-ec76fd50fbcd",
   "metadata": {},
   "source": [
    "## Training on whole image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54934841-935a-414c-9682-9ba78c11eb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 15:01:26.953581: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 15:01:27.038811: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-24 15:01:27.038824: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-24 15:01:27.056546: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-05-24 15:01:27.540972: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-24 15:01:27.541046: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-24 15:01:27.541053: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal\n",
    "#import gdal\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate, Reshape\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "#import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bcd1ea8-83ce-49b6-8bda-34f845fafd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58320 images belonging to 5 classes.\n",
      "Found 58320 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the paths to your image data directories\n",
    "x_train_dir = 'data/train_patch/'\n",
    "y_train_dir = 'data/train_label_patch/'\n",
    "\n",
    "# Set the image and batch size\n",
    "image_size = (512, 512)  # Target image size for resizing\n",
    "batch_size = 64\n",
    "\n",
    "# Data augmentation and normalization configuration for x_train\n",
    "x_train_generator = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # Scale pixel values to [0, 1]\n",
    "    rotation_range=20,  # Random rotation between -20 and 20 degrees\n",
    "    width_shift_range=0.2,  # Randomly shift images horizontally by 20% of the width\n",
    "    height_shift_range=0.2,  # Randomly shift images vertically by 20% of the height\n",
    "    horizontal_flip=True  # Randomly flip images horizontally\n",
    ")\n",
    "\n",
    "# Create an image generator for x_train\n",
    "x_train_image_generator = x_train_generator.flow_from_directory(\n",
    "    x_train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,  # Set to None to return only input images\n",
    "    shuffle=False  # Set to False to ensure x_train and y_train match\n",
    ")\n",
    "\n",
    "# Data normalization configuration for y_train\n",
    "y_train_generator = ImageDataGenerator(\n",
    "    rescale=1.0 / 255  # Scale pixel values to [0, 1]\n",
    ")\n",
    "\n",
    "# Create an image generator for y_train\n",
    "y_train_image_generator = y_train_generator.flow_from_directory(\n",
    "    y_train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,  # Set to None to return only input images\n",
    "    shuffle=False  # Set to False to ensure x_train and y_train match\n",
    ")\n",
    "\n",
    "# Ensure x_train and y_train generators have the same number of samples\n",
    "assert len(x_train_image_generator) == len(y_train_image_generator), \"Mismatch in x_train and y_train data\"\n",
    "train_data_generator = zip(x_train_image_generator, y_train_image_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3132ef9f-fbfb-421c-8d3b-1d0d688782f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def unet_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Encoder\n",
    "    #model.add(layers.Reshape((5000*5000*3, ), input_shape=(5000,5000, 3)))\n",
    "    #model.add(Reshape((5000*5000*3,), input_shape=(5000,5000,3))) \n",
    "\n",
    "    model.add(Conv2D(64, 3, activation='relu', padding='same', input_shape = ((512, 512, 3))))\n",
    "    model.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
    "    #model.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
    "    #model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, 3, activation='relu', padding='same'))\n",
    "    #model.add(Conv2D(256, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Decoder\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    #model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
    "\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    #model.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
    "\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(1, 3, activation='sigmoid', padding='same'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e8edce-e448-4cd8-9749-a89f40b79e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 15:01:42.210643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-24 15:01:42.210779: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-24 15:01:42.210888: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-24 15:01:42.210941: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-24 15:01:42.210988: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-24 15:01:42.211034: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-24 15:01:42.211080: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-24 15:01:42.211125: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-24 15:01:42.211170: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-05-24 15:01:42.211176: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-24 15:01:42.211586: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = unet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbcc1b92-78a8-4ade-b2eb-7542d8a54697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 512, 512, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 512, 512, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 256, 256, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 256, 256, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 128, 128, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 128, 128, 256)     295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 64, 64, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 128, 128, 256)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 128, 128, 128)     295040    \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 256, 256, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 256, 256, 64)      73792     \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 512, 512, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 512, 512, 1)       577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 777,153\n",
      "Trainable params: 777,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42c9d5e-7b69-47ff-bf4b-43627235c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    def dice_loss(y_true, y_pred):\n",
    "        y_pred = tf.math.sigmoid(y_pred)\n",
    "        numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "        denominator = tf.reduce_sum(y_true + y_pred)\n",
    "        return 1 - numerator / denominator\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    cross_entropy_loss = tf.nn.sigmoid_cross_entropy_with_logits(y_true, y_pred)\n",
    "    total_loss = cross_entropy_loss + dice_loss(y_true, y_pred)\n",
    "    return tf.reduce_mean(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e0ba9d5-dde6-4a60-9214-30f661755daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true, y_pred):\n",
    "    y_pred = tf.math.round(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    union = K.sum(y_true) + K.sum(y_pred) - intersection\n",
    "    iou = intersection / (union + K.epsilon())\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38532c5c-eae9-407e-aaa4-e51201216502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=loss, metrics=['accuracy', iou_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b7fc5c0-1e2b-4a49-a21f-cd25eb9863e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Activation, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2903021-dfbd-43b7-bd6b-a8a20e6ebb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the generator to train the model\n",
    "model.fit(\n",
    "    train_data_generator,\n",
    "    steps_per_epoch=len(x_train_image_generator),\n",
    "    epochs=1, batch_size = 32, verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda907e8-3df1-4dca-9e61-6efe36f6e777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
